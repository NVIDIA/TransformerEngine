{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Precision debug tools for the Transformer Engine use [Nvidia-DL-Framework-Inspect](https://github.com/NVIDIA/nvidia-dlfw-inspect) package from NVIDIA. Here, we provide brief information on how to use it with TE.\n",
    "\n",
    "### initialize()\n",
    "\n",
    "Must be called once on every rank in the global context to initialize Nvidia-DL-Framework-Inspect.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- **config_file** (*str*, default=\"\"): Path to the `config.yaml` file containing features to enable and layer names. If one wants to run without the config file, pass `\"\"`.\n",
    "- **feature_dirs** (*List[str] | str*): List of directories containing features to load and register. One needs to pass `[/path/to/transformerengine/transformer_engine/debug/features]` to use TE features.\n",
    "- **logger** (*Union[BaseLogger, None]*, default=None): Logger for logging tensor statistics. Should adhere to `BaseLogger` from the [Nvidia-DL-Framework-Inspect](0) package.\n",
    "- **log_dir** (*str*, default= \".\"): Directory path to hold `debug_logs` and `debug_statistics_logs`.\n",
    "- **tb_writer** (*TensorBoardWriter*, default=None): TensorBoard writer for logging.\n",
    "- **default_logging_enabled** (*bool*, default=False): Enable default logging to the file.\n",
    "\n",
    "```python\n",
    "import nvdlfw_inspect.api as debug_api\n",
    "\n",
    "debug_api.initialize(\n",
    "    config_file=\"./config.yaml\",\n",
    "    feature_dirs=[\"/path/to/transformer_engine/debug/features\"],\n",
    "    log_dir=\"./log_dir\")\n",
    "\n",
    "```\n",
    "\n",
    "### set_tensor_reduction_group()\n",
    "\n",
    "Needed only for logging tensor stats. In multi-GPU training, activation and gradient tensors are distributed across multiple nodes. This method lets you specify the group for the reduction of stats; see the [reduction group section](./4_distributed.ipynb#Reduction-groups) for more details.\n",
    "\n",
    "If the tensor reduction group is not specified, then statistics are reduced across all nodes in the run.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- **group** (torch.distributed.ProcessGroup): The process group across which tensors will be reduced to get stats.\n",
    "\n",
    "\n",
    "```python\n",
    "import nvdlfw_inspect.api as debug_api\n",
    "\n",
    "# initialization\n",
    "# (...)\n",
    "\n",
    "pipeline_parallel_group = initialize_pipeline_parallel_group() \n",
    "\n",
    "debug_api.set_tensor_reduction_group(pipeline_parallel_group)\n",
    "\n",
    "# training\n",
    "# (...)\n",
    "# activation/gradient tensor statistics are reduced along pipeline_parallel_group\n",
    "```\n",
    "\n",
    "### set_weight_tensor_tp_group_reduce()\n",
    "\n",
    "By default, weight tensor statistics are reduced within the tensor parallel group. This function allows you to disable that behavior; for more details, see [reduction group section](./4_distributed.ipynb#Reduction-groups).\n",
    "\n",
    "This method is not provided by the `debug_api`, but by the `transformer_engine.debug`.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- **enabled** (*bool*, default=True): A boolean flag to enable or disable the reduction of weight tensor statistics within the tensor parallel group.\n",
    "\n",
    "\n",
    "```python\n",
    "import nvdlfw_inspect.api as debug_api\n",
    "from transformer_engine.debug import set_weight_tensor_tp_group_reduce\n",
    "\n",
    "# initialization\n",
    "# (...)\n",
    "\n",
    "set_weight_tensor_tp_group_reduce(False)\n",
    "\n",
    "# training\n",
    "# (...)\n",
    "# weight tensor statistics are not reduced\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
